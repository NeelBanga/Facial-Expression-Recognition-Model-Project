{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://localhost:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [04/Sep/2020 10:54:23] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [04/Sep/2020 10:54:23] \"\u001b[35m\u001b[1mGET /video_feed HTTP/1.1\u001b[0m\" 500 -\n",
      "Error on request:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\neel\\Anaconda3\\Lib\\site-packages\\werkzeug\\serving.py\", line 323, in run_wsgi\n",
      "    execute(self.server.app)\n",
      "  File \"C:\\Users\\neel\\Anaconda3\\Lib\\site-packages\\werkzeug\\serving.py\", line 314, in execute\n",
      "    for data in application_iter:\n",
      "  File \"C:\\Users\\neel\\Anaconda3\\Lib\\site-packages\\werkzeug\\wsgi.py\", line 506, in __next__\n",
      "    return self._next()\n",
      "  File \"C:\\Users\\neel\\Anaconda3\\Lib\\site-packages\\werkzeug\\wrappers\\base_response.py\", line 45, in _iter_encoded\n",
      "    for item in iterable:\n",
      "  File \"<ipython-input-13-fe25b9ace714>\", line 14, in gen\n",
      "    \n",
      "  File \"C:\\Users\\neel\\Desktop\\Facial Expression Recognition with Keras Project\\Project\\camera.py\", line 19, in get_frame\n",
      "    gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
      "cv2.error: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-q0nmoxxv\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "from flask import Flask, render_template, Response\n",
    "from camera import VideoCamera\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "def gen(camera):\n",
    "    while True:\n",
    "        frame = camera.get_frame()\n",
    "        yield (b'--frame\\r\\n'\n",
    "               b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame + b'\\r\\n\\r\\n')\n",
    "\n",
    "@app.route('/video_feed')\n",
    "def video_feed():\n",
    "    return Response(gen(VideoCamera()),\n",
    "                    mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #app.run(host='0.0.0.0', debug=True)\n",
    "    app.run('localhost', 5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load camera.py\n",
    "import cv2\n",
    "from model import FacialExpressionModel\n",
    "import numpy as np\n",
    "\n",
    "facec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "model = FacialExpressionModel(\"model.json\", \"model_weights.h5\")\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "class VideoCamera(object):\n",
    "    def __init__(self):\n",
    "        self.video = cv2.VideoCapture('C:/Users/neel/Desktop/Facial Expression Recognition with Keras Project/Project/videos/facial_exp.mkv')\n",
    "\n",
    "    def __del__(self):\n",
    "        self.video.release()\n",
    "\n",
    "    # returns camera frames along with bounding boxes and predictions\n",
    "    def get_frame(self):\n",
    "        _, fr = self.video.read()\n",
    "        gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
    "        faces = facec.detectMultiScale(gray_fr, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            fc = gray_fr[y:y+h, x:x+w]\n",
    "\n",
    "            roi = cv2.resize(fc, (48, 48))\n",
    "            pred = model.predict_emotion(roi[np.newaxis, :, :, np.newaxis])\n",
    "\n",
    "            cv2.putText(fr, pred, (x, y), font, 1, (255, 255, 0), 2)\n",
    "            cv2.rectangle(fr,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        _, jpeg = cv2.imencode('.jpg', fr)\n",
    "        return jpeg.tobytes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load model.py\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.15\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "set_session(session)\n",
    "\n",
    "\n",
    "class FacialExpressionModel(object):\n",
    "\n",
    "    EMOTIONS_LIST = [\"Angry\", \"Disgust\",\n",
    "                     \"Fear\", \"Happy\",\n",
    "                     \"Neutral\", \"Sad\",\n",
    "                     \"Surprise\"]\n",
    "\n",
    "    def __init__(self, model_json_file, model_weights_file):\n",
    "        # load model from JSON file\n",
    "        with open(model_json_file, \"r\") as json_file:\n",
    "            loaded_model_json = json_file.read()\n",
    "            self.loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "        # load weights into the new model\n",
    "        self.loaded_model.load_weights(model_weights_file)\n",
    "        #self.loaded_model.compile()\n",
    "        #self.loaded_model._make_predict_function()\n",
    "\n",
    "    def predict_emotion(self, img):\n",
    "        global session\n",
    "        set_session(session)\n",
    "        self.preds = self.loaded_model.predict(img)\n",
    "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
